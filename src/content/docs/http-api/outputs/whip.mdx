---
title: WHIP client
hide_table_of_contents: true
---
import { Aside, Badge } from '@astrojs/starlight/components';
import CollapsibleDetails from '@components/CollapsibleDetails.astro';

An output that lets you connect to a WHIP server endpoint to stream video and audio to it.

## Usage
To use WHIP Output you must register it first. You can do it by sending a request like this:

<CollapsibleDetails summaryTitle='Example request' open>

```http
POST: /api/output/:output_id/register
Content-Type: application/json

{
  "type": "whip_client",
  "endpoint_url": "https://example.com/whip",
  "bearer_token": "<TOKEN>",
  "video": {
    "resolution": { "width": 1280, "height": 720 },
    "encoder_preferences": [
      { "type": "ffmpeg_h264", "preset": "ultrafast" },
      { "type": "ffmpeg_vp8" },
      { "type": "any" }
    ],
    "initial": {
      "root": {
        "type": "view"
      }
    }
  },
  "audio": {
    "channels": "stereo",
    "initial": {
      "inputs": [{ "input_id": "input_1", "volume": 1 }]
    }
  }
}
```
</CollapsibleDetails>

<Aside>
To enable compatibility with Twitch `video.encoder_preferences` must contain only a single `ffmpeg_h264` entry: 
```http
"encoder_preferences": [
  { 
    "type": "ffmpeg_h264"
  }
]
```
</Aside>

## Reference 

<CollapsibleDetails summaryTitle='Type definitions' open>

```tsx
type WhipClient = {
  type: "whip_client";
  endpoint_url: string;
  bearer_token?: string;
  video?: VideoOptions;
  audio?: AudioOptions;
};
```
</CollapsibleDetails>

Parameters for an WHIP output stream from Smelter.

## Properties

### endpoint_url
The destination URL for sending media streams using the WHIP.

 - **Type**: `string`

### bearer_token
Token used for authentication when connecting to the WHIP endpoint.

 - **Type**: `string`


### video
Parameters of a video included in the WHIP stream.

- **Type**: [`VideoOptions`](#videooptions)

---

### audio
Parameters of an audio included in the WHIP stream.

- **Type**: [`AudioOptions`](#audiooptions)

## VideoOptions
Parameters of a video source included in the WHIP stream.

<CollapsibleDetails summaryTitle='Type definitions' open>
```tsx
type VideoOptions = {
  resolution: {
    width: u32;
    height: u32;
  };
  send_eos_when?: OutputEndCondition;
  encoder_preferences?: VideoEncoderOptions[];
  initial: { root: Component; };
};
```
</CollapsibleDetails>

### Properties

#### resolution
Output resolution in pixels.

- **Type**: `{ width: number; height: number; }`

---

#### send_eos_when
Condition for termination of the output stream based on the input streams states. If output includes both audio and video streams, then EOS needs to be sent for every type.

- **Type**: [`OutputEndCondition`](#outputendcondition)

---

#### encoder_preferences
An ordered list of preferred video encoders. The first element in the list has the highest priority during WHIP negotiation.

- **Type**: [`VideoEncoderOptions`](#videoencoderoptions)[]
- **Default value**: `[{ type: "any" }]`

Behavior:
- If the list ends with "any":
  - Smelter will first try the encoders explicitly listed (in order) and use the first one that is supported and negotiated in WHIP signaling.
  - If none of the listed encoders are supported, Smelter will fall back to any supported codec from the negotiated list that wasn’t already in the preferences.

- If "any" is not included:
  - Only the encoders listed will be considered.
  - If none are supported, no fallback will occur.



---

#### initial
Root of a component tree/scene that should be rendered for the output.

- **Type**: `{ root: Component; }`


## VideoEncoderOptions
Configuration for the video encoder, based on the selected codec.

<CollapsibleDetails summaryTitle='Type definitions' open>
```tsx
type VideoEncoderOptions =
  | {
      type: "ffmpeg_h264";
      preset?:
        | "ultrafast"
        | "superfast"
        | "veryfast"
        | "faster"
        | "fast"
        | "medium"
        | "slow"
        | "slower"
        | "veryslow"
        | "placebo";
      pixel_format?: "yuv420p" | "yuv422p" | "yuv444p";
      ffmpeg_options?: Map<string, string>;
    }
  | {
      type: "ffmpeg_vp8";
      ffmpeg_options?: Map<string, string>;
    }
  | {
      type: "ffmpeg_vp9";
      pixel_format?: "yuv420p" | "yuv422p" | "yuv444p";
      ffmpeg_options?: Map<string, string>;
    }
  | {
      type: "vulkan_h264";
      bitrate: { average_bitrate: number; max_bitrate: number; } | number;
    }
  | {
      type: "any";
    };
```
</CollapsibleDetails>

### Properties (type: “ffmpeg_h264”)

#### preset
Video output encoder preset. Visit <a href='https://trac.ffmpeg.org/wiki/Encode/H.264#Preset' target='_blank'>FFmpeg docs</a> to learn more.

- **Type**: `"ultrafast" | "superfast" | "veryfast" | "faster" | "fast" | "medium" | "slow" | "slower" | "veryslow" | "placebo"`
- **Default value**: `fast`
- **Supported values**:
  - `ultrafast`
  - `superfast`
  - `veryfast`
  - `faster`
  - `fast`
  - `medium`
  - `slow`
  - `slower`
  - `veryslow`
  - `placebo`

---

#### pixel_format
Encoder pixel format

- **Type**: `"yuv420p" | "yuv422p" | "yuv444p"`
- **Default value**: `yuv420p`
- **Supported values**:
  - `yuv420p`
  - `yuv422p`
  - `yuv444p`

---

#### ffmpeg_options
Raw FFmpeg encoder options. Visit <a href='https://ffmpeg.org/ffmpeg-codecs.html' target='_blank'>FFmpeg docs</a> to learn more.

- **Type**: `Map<string, string>`

### Properties (type: “ffmpeg_vp8”)

#### ffmpeg_options
Raw FFmpeg encoder options. Visit <a href='https://ffmpeg.org/ffmpeg-codecs.html' target='_blank'>FFmpeg docs</a> to learn more.

- **Type**: `Map<string, string>`

### Properties (type: “ffmpeg_vp9”)

#### pixel_format
Encoder pixel format

- **Type**: `"yuv420p" | "yuv422p" | "yuv444p"`
- **Default value**: `yuv420p`
- **Supported values**:
  - `yuv420p`
  - `yuv422p`
  - `yuv444p`

---

#### ffmpeg_options
Raw FFmpeg encoder options. Visit <a href='https://ffmpeg.org/ffmpeg-codecs.html' target='_blank'>FFmpeg docs</a> to learn more.

- **Type**: `Map<string, string>`

### Properties (type: “vulkan_h264”) <Badge text="Required feature:vk-video" variant="note" />
Hardware encoder based on Vulkan Video.

This should be faster and more scalable than the FFmpeg encoder, if the hardware and OS
support it.

This requires hardware that supports Vulkan Video. Another requirement is this program has
to be compiled with the `vk-video` feature enabled (enabled by default on platforms which
support Vulkan, i.e. non-Apple operating systems and not the web).

#### bitrate
Encoding bitrate. If not provided, bitrate is calculated based on resolution and framerate. For example at 1080p 30 FPS the average bitrate is 5000 kbit/s and max bitrate is 6250 kbit/s.

<CollapsibleDetails summaryTitle='Type definitions' open>
```tsx
type VulkanH264EncoderBitrate = { average_bitrate: number; max_bitrate: number; } | number;
```
</CollapsibleDetails>

#### Properties

##### average_bitrate
Average bitrate measured in bits/second. Encoder will try to keep the bitrate around the provided average, but may temporarily increase it to the provided max bitrate.

---

##### max_bitrate
Max bitrate measured in bits/second.

## AudioOptions
Parameters of an audio source included in the WHIP stream.

<CollapsibleDetails summaryTitle='Type definitions' open>
```tsx
type AudioOptions = {
  mixing_strategy?: "sum_clip" | "sum_scale";
  send_eos_when?: OutputEndCondition;
  encoder_preferences?: AudioEncoderOptions[];
  channels?: "mono" | "stereo";
  initial: { inputs: InputAudio[]; };
}
```
</CollapsibleDetails>

### Properties

#### mixing_strategy
Specifies how audio should be mixed.

- **Type**: `"sum_clip" | "sum_scale"`
- **Default value**: `"sum_clip"`
- **Supported values**:
  - `sum_clip` - First, the input samples are summed. If the result exceeds the i16 PCM range, it is clipped.
  - `sum_scale` - First, the input samples are summed. If the result exceeds the i16 PCM range, the summed samples are scaled down by a factor to fit within the range.

---

#### send_eos_when
Condition for termination of the output stream based on the input streams states. If output includes both audio and video streams, then EOS needs to be sent for every type.

- **Type**: [`OutputEndCondition`](#outputendcondition)

---

#### encoder_preferences
An ordered list of preferred audio encoders. The first element in the list has the highest priority during WHIP negotiation.
- **Type**: [`AudioEncoderOptions`](#audioencoderoptions)[]
- **Default value**: `[{ type: "any" }]`

Behavior:
- If the list ends with "any":
  - Smelter will first try the encoders explicitly listed (in order) and use the first one that is supported and negotiated in WHIP signaling.
  - If none of the listed encoders are supported, Smelter will fall back to any supported codec from the negotiated list that wasn’t already in the preferences.

- If "any" is not included:
  - Only the encoders listed will be considered.
  - If none are supported, no fallback will occur.


---

#### channels
Channels configuration

- **Type**: `"mono" | "stereo"`
- **Default value**: `"stereo"`
- **Supported values**:
    - `mono` - Mono audio (single channel).
    - `stereo` - Stereo audio (two channels).

---

#### initial
Initial audio mixer configuration for output.

- **Type**: `{ inputs: InputAudio[]; }`

## AudioEncoderOptions
Configuration for the audio encoder.

<CollapsibleDetails summaryTitle='Type definitions' open>
```tsx
type AudioEncoderOptions = {
  type: "opus";
  preset?: "quality" | "voip" | "lowest_latency";
  sample_rate?: u32;
  forward_error_correction?: bool;
} | {
  type: "any";
}
```
</CollapsibleDetails>

### Properties(type: "opus")

#### preset
Audio output encoder preset.

- **Type**: `"quality" | "voip" | "lowest_latency"`
- **Default value**: `voip`
- **Supported values**:
    - `quality` - Recommended for broadcast and high-fidelity applications requiring decoded audio to maintain maximum fidelity to the input signal.
    - `voip` - Recommended for VoIP and videoconferencing applications, prioritizing listening quality and speech intelligibility.
    - `lowest_latency` - Recommended **only** when achieving the lowest possible latency is the highest priority.

#### sample_rate
Sample rate for audio encoder.

- **Type**: `u32`
- **Default value**: `48000`
- **Supported values**: `8000`, `16000`, `24000`, `48000`.

#### forward_error_correction
When enabled, include in-band forward error correction data to protect against packet loss. For more information, visit RFC specification sections [2.1.7](https://datatracker.ietf.org/doc/html/rfc6716#section-2.1.7)
and [4.2.5](https://datatracker.ietf.org/doc/html/rfc6716#section-4.2.5)

- **Type**: `bool`
- **Default value**: `false`

---

### Properties(type: "any")
Specifies that any audio encoder supported by Smelter can be used. If `"any"` is not included in the `encoder_preferences` list, Smelter will only use the encoders explicitly listed in the preferences.

## InputAudio
<CollapsibleDetails summaryTitle='Type definitions' open>
```tsx
type InputAudio = {
  input_id: string;
  volume?: f32;
}
```
</CollapsibleDetails>

### Properties

#### input_id
ID of an input. It identifies a stream registered using a [register input](/http-api/routes#register-input) method.

- **Type**: `string`

#### volume
Input volume in range `[0, 2]`

- **Type**: `f32`
- **Default value**: `1.0`
- **Supported values**: `[0, 2]`

## OutputEndCondition
Defines when the output stream should end based on the state of the input streams. Only one of the nested fields can be set at a time. 

By default, the input stream is considered finished/ended when:
- TCP connection was dropped/closed.
- RTCP Goodbye packet (BYE) was received.
- MP4 track has ended.
- Input was unregistered already (or never registered).

<CollapsibleDetails summaryTitle='Type definitions' open>
```tsx
type OutputEndCondition = 
  | { any_of: string[]; }
  | { all_of: string[]; }
  | { any_input: bool; }
  | { all_inputs: bool; };
```
</CollapsibleDetails>

### Properties

#### any_of
List of the input streams. The output stream will terminate if any stream in the list finishes.

- **Type**: `string[]`

---

#### all_of
List of the input streams. The output stream will terminate when all streams in the list finish.

- **Type**: `string[]`

---

#### any_input
Terminate the output stream if any of the input streams end, including streams added after the output was registered. Notably, the output stream will not terminate if no inputs were ever connected.

- **Type**: `bool`

---

#### all_inputs
Terminate the output stream only when all input streams have finished. Notably, the output stream will terminate if no inputs were ever connected.

- **Type**: `bool`

