---
title: WHEP server
---
import { Badge, Aside } from '@astrojs/starlight/components';
import CollapsibleDetails from '@components/CollapsibleDetails.astro';

<Badge text="Node.js" variant="tip" size="large" />
<Badge text="Browser (Client)" variant="tip" size="large" />

<br />
<br />

An output type that provides a WHEP server endpoint. It allows broadcasting a media stream to multiple clients simultaneously.

Smelter exposes WHEP endpoint on port 9000 under `/whep/:output_id` route. A different port can be
configured with [`SMELTER_WHIP_WHEP_SERVER_PORT`](/deployment/configuration#smelter_whip_whep_server_port).

To connect new output, register it first with `Smelter.registerOutput`. This function returns an object
containing the `endpointRoute` for the WHEP stream. You can then use this route to establish a WHEP connection.

<Aside>
  This output complies with the WHEP specification described in [draft-ietf-wish-whep-02](https://datatracker.ietf.org/doc/html/draft-ietf-wish-whep-02).
</Aside>

## Usage

```tsx title=whepServerOutputExample.tsx
import Smelter from "@swmansion/smelter-node";
import { View } from "@swmansion/smelter";

async function run() {
  const smelter = new Smelter();
  await smelter.init();
  const { endpointRoute } = await smelter.registerOutput("example", <View />, {
    type: "whep_server",
    video: {
      encoder: { type: "ffmpeg_h264" },
      resolution: { width: 1920, height: 1080 },
    }
  });
  // In this example, endpointRoute resolves to "/whep/example"
}
void run();
```

## Reference

<CollapsibleDetails summaryTitle='Type definitions' open>

```tsx
type RegisterWhepServerOutput = {
  type: "whep_server";
  bearerToken?: string;
  video?: VideoOptions;
  audio?: AudioOptions;
}
```
</CollapsibleDetails>

Parameters for registering an output that sends composed video/audio as an WHEP stream.

## Properties

### bearerToken
Authentication token. If not provided, authentication is not required.

- **Type**: `string`

---

### video
Parameters of a video included in the WHEP stream.

- **Type**: [`VideoOptions`](#videooptions)

---

### audio
Parameters of an audio included in the WHEP stream.

- **Type**: [`AudioOptions`](#audiooptions)

## VideoOptions

<CollapsibleDetails summaryTitle='Type definitions' open>
```tsx
type VideoOptions = {
    resolution: {
      width: number;
      height: number;
    };
    sendEosWhen?: OutputEndCondition;
    encoder: VideoEncoderOptions;
}
```
</CollapsibleDetails>

Parameters of a video source included in the WHEP stream.

### Properties

#### resolution
Output resolution in pixels.

- **Type**: `{ width: number; height: number;}`

---

#### sendEosWhen
Condition for termination of the output stream based on the input streams states. If output includes both audio and video streams, then EOS needs to be sent for every type.

- **Type**: [`OutputEndCondition`](#outputendcondition)

---

#### encoder
Video encoder options.

- **Type**: [`VideoEncoderOptions`](#videoencoderoptions)


## VideoEncoderOptions

<CollapsibleDetails summaryTitle='Type definitions' open>

```tsx
type VideoEncoderOptions = 
  | ({ type: "ffmpeg_h264"; } & FfmpegH264EncoderOptions)
  | ({ type: "ffmpeg_vp8"; } & FfmpegVp8EncoderOptions)
  | ({ type: "ffmpeg_vp9"; } & FfmpegVp9EncoderOptions)
  | ({ type: "vulkan_h264"; } & VulkanH264EncoderOptions);
```
</CollapsibleDetails>

Configuration for the video encoder, based on the selected codec. Visit encoder documentation to learn more.

- [FFmpeg H264](/ts-sdk/outputs/encoders/ffmpeg-h264)
- [FFmpeg VP8](/ts-sdk/outputs/encoders/ffmpeg-vp8)
- [FFmpeg VP9](/ts-sdk/outputs/encoders/ffmpeg-vp9)
- [Vulkan H264](/ts-sdk/outputs/encoders/vulkan-h264)

## AudioOptions

<CollapsibleDetails summaryTitle='Type definitions' open>

```tsx
type AudioOptions = {
  channels?: "mono" | "stereo";
  mixingStrategy?: "sum_clip" | "sum_scale";
  sendEosWhen?: OutputEndCondition;
  encoder: AudioEncoderOptions;
}
```
</CollapsibleDetails>

Parameters of an audio source included in the WHEP stream.

### Properties

#### channels
Channels configuration

- **Type**: `"mono" | "stereo"`
- **Default value**: `"stereo"`
- **Supported values**:
    - `mono` - Mono audio (single channel).
    - `stereo` - Stereo audio (two channels).

---

#### mixingStrategy
Specifies how audio should be mixed.

- **Type**: `"sum_clip" | "sum_scale"`
- **Default value**: `"sum_clip"`
- **Supported values**:
    - `sum_clip` - First, the input samples are summed. If the result exceeds the i16 PCM range, it is clipped.
    - `sum_scale` - First, the input samples are summed. If the result exceeds the i16 PCM range, the summed samples are scaled down by a factor to fit within the range.

---

#### sendEosWhen
Condition for termination of the output stream based on the input streams states. If output includes both audio and video streams, then EOS needs to be sent for every type.

- **Type**: [`OutputEndCondition`](#outputendcondition)

---

#### encoder
Audio encoder options.

- **Type**: [`AudioEncoderOptions`](#audioencoderoptions)

## AudioEncoderOptions

<CollapsibleDetails summaryTitle='Type definitions' open>
```tsx
type AudioEncoderOptions = {
    type: "opus";
    preset?: "quality" | "voip" | "lowest_latency";
    sampleRate?: u32;
    forwardErrorCorrection?: boolean;
    expectedPacketLoss?: number;
  }
```
</CollapsibleDetails>

Configuration for the audio encoder, based on the selected codec.

### Properties(type: "opus")

#### preset
Audio output encoder preset.

- **Type**: `"quality" | "voip" | "lowest_latency"`
- **Default value**: `voip`
- **Supported values**:
    - `quality` - Recommended for broadcast and high-fidelity applications requiring decoded audio to maintain maximum fidelity to the input signal.
    - `voip` - Recommended for VoIP and videoconferencing applications, prioritizing listening quality and speech intelligibility.
    - `lowest_latency` - Recommended **only** when achieving the lowest possible latency is the highest priority.

--- 

#### sampleRate
Sample rate.

- **Type**: `u32`
- **Default value**: `48000`
- **Supported values**: `8000`, `16000`, `24000`, `48000`

---

#### forwardErrorCorrection
When enabled, include in-band forward error correction data to protect against packet loss. For more information, visit RFC specification sections [2.1.7](https://datatracker.ietf.org/doc/html/rfc6716#section-2.1.7)
and [4.2.5](https://datatracker.ietf.org/doc/html/rfc6716#section-4.2.5)

- **Type**: `bool`
- **Default value**: `false`

---

#### expectedPacketLoss
Expected packet loss expressed as a percentage. This value controls how much redundant data is added to counteract packet loss (only when forward error correction is enabled).

- **Type**: `u32`
- **Default value**: `0`
- **Supported values**: `0-100`

## OutputEndCondition

<CollapsibleDetails summaryTitle='Type definitions' open>
```tsx
type OutputEndCondition = 
  | { anyOf: string[]; }
  | { allOf: string[]; }
  | { anyInput: boolean; }
  | { allInputs: boolean; };
```
</CollapsibleDetails>

Defines when the output stream should end based on the state of the input streams. Only one of the nested fields can be set at a time. 

By default, the input stream is considered finished/ended when:
- TCP connection was dropped/closed.
- RTCP Goodbye packet (BYE) was received.
- MP4 track has ended.
- Input was unregistered already (or never registered).

### Properties

#### anyOf
List of the input streams. The output stream will terminate if any stream in the list finishes.

- **Type**: `string[]`

---

#### allOf
List of the input streams. The output stream will terminate when all streams in the list finish.

- **Type**: `string[]`

---

#### anyInput
Terminate the output stream if any of the input streams end, including streams added after the output was registered. Notably, the output stream will not terminate if no inputs were ever connected.

- **Type**: `boolean`

---

#### allInputs
Terminate the output stream only when all input streams have finished. Notably, the output stream will terminate if no inputs were ever connected.

- **Type**: `boolean`
